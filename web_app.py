from flask import Flask, render_template, request, send_file, jsonify
from werkzeug.utils import secure_filename
import os
import tempfile
import uuid
import json
try:
    import whisper
    WHISPER_AVAILABLE = True
except ImportError:
    WHISPER_AVAILABLE = False
    print("⚠️  Whisper not available - only ElevenLabs transcription will work")
import requests
import re
from datetime import datetime
from openai import OpenAI
from main import get_insights_from_llm, format_marp_presentation
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

app = Flask(__name__)
UPLOAD_FOLDER = tempfile.gettempdir()

def generate_markdown_content(transcript, insights, transcript_info):
    """Generate markdown content for download"""
    content = f"""# InsightDeck Analysis Report

## Transcription Details
- **Service**: {transcript_info.get('service', 'Unknown')}
- **Language**: {transcript_info.get('language', 'Auto-detected')}
- **Speaker Diarization**: {'✅ Enabled' if transcript_info.get('has_speakers') else '❌ Not available'}
- **Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## Executive Summary
{insights.get('summary', 'Summary not available')}

## Key Themes
"""
    
    if insights.get('themes'):
        for i, theme in enumerate(insights['themes'], 1):
            content += f"{i}. {theme}\n"
    else:
        content += "No themes identified\n"
    
    content += f"""
## Full Transcription
{transcript}

---
*Generated by InsightDeck - AI-Powered Meeting Analysis*
"""
    
    return content

def transcribe_with_elevenlabs(audio_file_path, enable_diarization=True):
    """
    Transcribe audio using ElevenLabs Speech-to-Text with speaker diarization.
    Returns: dict with transcription results and speaker information
    """
    api_key = os.getenv('ELEVENLABS_API_KEY')
    if not api_key:
        raise ValueError("ElevenLabs API key not found. Please set ELEVENLABS_API_KEY environment variable.")
    
    if api_key == 'your_elevenlabs_api_key_here':
        raise ValueError("Please update your ElevenLabs API key in the .env file.")
    
    url = "https://api.elevenlabs.io/v1/speech-to-text/convert"
    
    headers = {
        "xi-api-key": api_key
    }
    
    try:
        # Prepare form data
        with open(audio_file_path, 'rb') as audio_file:
            files = {
                'audio': (os.path.basename(audio_file_path), audio_file, 'audio/mpeg')
            }
            
            data = {
                'model': 'eleven_turbo_v2_5',
                'language': 'en',  # Auto-detect or specify language
            }
            
            # Add diarization parameters if enabled
            if enable_diarization:
                data['num_speakers'] = 8  # Up to 8 speakers (adjust as needed)
                data['diarization_threshold'] = 0.3  # Balance between accuracy and speaker count
                data['tag_audio_events'] = True  # Include laughter, applause, etc.
            
            print("Sending request to ElevenLabs API...")
            response = requests.post(url, headers=headers, files=files, data=data, timeout=300)
        
        # Handle specific error cases
        if response.status_code == 401:
            raise Exception("ElevenLabs API authentication failed. Please check your API key.")
        elif response.status_code == 403:
            raise Exception("ElevenLabs API access denied. Your API key doesn't have Speech-to-Text permissions. Please upgrade your plan or contact ElevenLabs support.")
        elif response.status_code == 429:
            raise Exception("ElevenLabs API rate limit exceeded. Please try again later.")
        elif response.status_code != 200:
            error_detail = ""
            try:
                error_json = response.json()
                error_detail = f" - {error_json.get('detail', 'Unknown error')}"
            except:
                error_detail = f" - {response.text}"
            raise Exception(f"ElevenLabs API error: {response.status_code}{error_detail}")
        
        result = response.json()
        
        # Parse the response to extract speaker information
        transcript_text = ""
        speaker_segments = []
        
        if 'text' in result:
            transcript_text = result['text']
        
        # Parse words with speaker information
        if 'words' in result and result['words']:
            current_speaker = None
            current_segment = ""
            
            for word_info in result['words']:
                word = word_info.get('text', '')
                speaker_id = word_info.get('speaker_id')
                
                if speaker_id != current_speaker:
                    # Save previous segment
                    if current_segment.strip():
                        speaker_segments.append({
                            'speaker': f"Speaker {current_speaker}" if current_speaker else "Unknown",
                            'text': current_segment.strip()
                        })
                    
                    # Start new segment
                    current_speaker = speaker_id
                    current_segment = word
                else:
                    current_segment += " " + word
            
            # Add the last segment
            if current_segment.strip():
                speaker_segments.append({
                    'speaker': f"Speaker {current_speaker}" if current_speaker else "Unknown",
                    'text': current_segment.strip()
                })
        
        # Format transcript with speakers if available
        if speaker_segments and enable_diarization:
            formatted_transcript = ""
            for segment in speaker_segments:
                formatted_transcript += f"[{segment['speaker']}]: {segment['text']}\n\n"
            transcript_text = formatted_transcript
        
        return {
            'text': transcript_text,
            'has_speakers': bool(speaker_segments and enable_diarization),
            'speaker_count': len(set(word.get('speaker_id') for word in result.get('words', []) if word.get('speaker_id'))) if enable_diarization else 0,
            'service': 'elevenlabs',
            'language': result.get('language_code', 'unknown')
        }
    
    except requests.exceptions.Timeout:
        raise Exception("ElevenLabs API request timed out. The audio file might be too large or the service is busy.")
    except requests.exceptions.RequestException as e:
        raise Exception(f"Network error while connecting to ElevenLabs API: {str(e)}")
    except Exception as e:
        # Re-raise our custom exceptions
        if "ElevenLabs API" in str(e):
            raise e
        else:
            raise Exception(f"Error processing ElevenLabs transcription: {str(e)}")


def transcribe_with_whisper(audio_file_path):
    """
    Transcribe audio using OpenAI Whisper (local model).
    """
    if not WHISPER_AVAILABLE:
        raise Exception("Whisper is not installed. Please use ElevenLabs transcription instead.")
    
    try:
        # Load Whisper model (using 'base' model for balance of speed and accuracy)
        print("Loading Whisper model...")
        model = whisper.load_model("base")
        
        # Transcribe the audio
        print(f"Transcribing audio file with Whisper: {audio_file_path}")
        result = model.transcribe(audio_file_path)
        
        return {
            'text': result['text'].strip(),
            'has_speakers': False,  # Whisper doesn't provide speaker diarization
            'speaker_count': 0,
            'service': 'whisper',
            'language': result.get('language', 'unknown')
        }
    
    except Exception as e:
        raise Exception(f"Error processing Whisper transcription: {str(e)}")


@app.route('/')
def index():
    """Main page with upload interface."""
    return render_template('index.html')

@app.route('/settings')
def settings():
    """Settings page for API key management."""
    return render_template('settings.html')

@app.route('/transcribe_only', methods=['POST'])
def transcribe_only():
    """Transcribe audio/text files and return transcript for preview without AI analysis."""
    try:
        text_content = None
        transcription_info = {'service': 'Unknown', 'has_speakers': False}
        
        # Handle file upload
        if 'file' in request.files:
            file = request.files['file']
            if file and file.filename:
                filename = secure_filename(file.filename)
                file_extension = os.path.splitext(filename)[1].lower()
                
                # Handle audio files
                audio_extensions = ['.mp3', '.wav', '.m4a', '.mp4', '.flac', '.ogg']
                if file_extension in audio_extensions:
                    # Save audio file temporarily
                    audio_file_path = os.path.join(UPLOAD_FOLDER, filename)
                    file.save(audio_file_path)
                    
                    service_type = request.form.get('service_type', 'whisper')
                    enable_diarization = request.form.get('enable_diarization') == 'true'
                    
                    print(f"Transcribing audio file: {filename}")
                    print(f"Using service: {service_type}")
                    
                    try:
                        if service_type == 'elevenlabs' and enable_diarization:
                            print("Transcribing with ElevenLabs (speaker diarization enabled)...")
                            result = transcribe_with_elevenlabs(audio_file_path, enable_diarization=True)
                            text_content = result['text']
                            transcription_info = {
                                'service': 'ElevenLabs',
                                'has_speakers': result.get('has_speakers', False),
                                'speaker_count': result.get('speaker_count', 0),
                                'language': result.get('language', 'unknown')
                            }
                            print(f"ElevenLabs transcription completed: {len(text_content)} characters")
                            if result.get('has_speakers'):
                                print(f"Speaker diarization: {result.get('speaker_count', 0)} speakers detected")
                        else:
                            # Use Whisper (free)
                            print("Transcribing with OpenAI Whisper...")
                            result = transcribe_with_whisper(audio_file_path)
                            if result and 'text' in result:
                                text_content = result['text']
                                transcription_info = {
                                    'service': 'OpenAI Whisper',
                                    'has_speakers': False,
                                    'speaker_count': 0,
                                    'language': result.get('language', 'unknown')
                                }
                                print(f"Whisper transcription completed: {len(text_content)} characters")
                            else:
                                return jsonify({'error': 'Failed to transcribe audio with Whisper'}), 500
                        
                        # Clean up temporary file
                        try:
                            os.remove(audio_file_path)
                        except:
                            pass
                            
                    except Exception as e:
                        print(f"Transcription error: {str(e)}")
                        # Clean up temporary file on error
                        try:
                            os.remove(audio_file_path)
                        except:
                            pass
                        return jsonify({'error': f'Failed to transcribe audio: {str(e)}'}), 500
                
                # Handle text files
                elif file_extension == '.txt':
                    text_content = file.read().decode('utf-8').strip()
                    transcription_info = {'service': 'Text File Upload', 'has_speakers': False}
        
        # Handle pasted text
        elif request.form.get('text_content'):
            text_content = request.form.get('text_content', '').strip()
            transcription_info = {'service': 'Manual Input', 'has_speakers': False}
        
        if not text_content:
            return jsonify({'error': 'No content provided. Please upload a file or paste text.'}), 400
        
        # Analyze transcript for speaker information (in case speakers were manually added)
        if '[Speaker' in text_content or any(line.strip().endswith(':') for line in text_content.split('\n')[:10]):
            speaker_matches = re.findall(r'\[(Speaker \d+|[^:\]]+)\]:|^([^:\n]+):', text_content, re.MULTILINE)
            if speaker_matches:
                unique_speakers = set()
                for match in speaker_matches:
                    speaker = match[0] if match[0] else match[1]
                    if speaker.strip():
                        unique_speakers.add(speaker.strip())
                
                if len(unique_speakers) > 1:
                    transcription_info['has_speakers'] = True
                    transcription_info['speaker_count'] = len(unique_speakers)
        
        # Return just the transcript data for preview
        return jsonify({
            'success': True,
            'transcript': text_content,
            'service': transcription_info['service'],
            'has_speakers': transcription_info.get('has_speakers', False),
            'speaker_count': transcription_info.get('speaker_count', 0),
            'language': transcription_info.get('language', 'Auto-detected'),
            'word_count': len(text_content.split()) if text_content else 0
        })
    
    except Exception as e:
        print(f"Transcription error: {str(e)}")
        return jsonify({'error': f'Failed to process file: {str(e)}'}), 500


@app.route('/process', methods=['POST'])
def process_transcript():
    """Process uploaded transcript or audio file and return insights."""
    try:
        # Get processing options
        service_type = request.form.get('service_type', 'whisper')  # 'whisper' or 'elevenlabs'
        enable_diarization = request.form.get('enable_diarization', 'false').lower() == 'true'
        
        # Get the uploaded content
        text_content = ""
        audio_file_path = None
        transcription_info = {}
        
        if 'file' in request.files and request.files['file'].filename:
            file = request.files['file']
            filename = file.filename.lower()
            
            # Check if it's an audio file
            audio_extensions = ['.mp3', '.wav', '.m4a', '.mp4', '.flac', '.ogg']
            if any(filename.endswith(ext) for ext in audio_extensions):
                # Save uploaded audio file temporarily
                audio_file_path = os.path.join(UPLOAD_FOLDER, f"audio_{uuid.uuid4().hex[:8]}{os.path.splitext(filename)[1]}")
                file.save(audio_file_path)
                
                print(f"Processing audio file: {filename}")
                print(f"Using service: {service_type}")
                
                try:
                    if service_type == 'elevenlabs' and enable_diarization:
                        print("Transcribing with ElevenLabs (speaker diarization enabled)...")
                        result = transcribe_with_elevenlabs(audio_file_path, enable_diarization=True)
                        text_content = result['text']
                        transcription_info = {
                            'service': 'ElevenLabs',
                            'has_speakers': result.get('has_speakers', False),
                            'speaker_count': result.get('speaker_count', 0),
                            'language': result.get('language', 'unknown')
                        }
                        print(f"ElevenLabs transcription completed: {len(text_content)} characters")
                        if result.get('has_speakers'):
                            print(f"Speaker diarization: {result.get('speaker_count', 0)} speakers detected")
                    
                    else:
                        # Default to Whisper
                        if not WHISPER_AVAILABLE:
                            return jsonify({'success': False, 'error': 'Whisper is not installed. Please select ElevenLabs for transcription.'}), 400
                        
                        print("Transcribing with OpenAI Whisper (no speaker separation)...")
                        model = whisper.load_model("base")
                        result = model.transcribe(audio_file_path)
                        text_content = result["text"]
                        transcription_info = {
                            'service': 'OpenAI Whisper',
                            'has_speakers': False,
                            'speaker_count': 0,
                            'language': result.get("language", "unknown")
                        }
                        print(f"Whisper transcription completed: {len(text_content)} characters")
                
                except Exception as e:
                    return jsonify({'error': f'Audio transcription failed: {str(e)}'}), 500
                finally:
                    # Clean up audio file
                    if os.path.exists(audio_file_path):
                        os.remove(audio_file_path)
            else:
                # Text file
                text_content = file.read().decode('utf-8')
                transcription_info = {'service': 'Manual Upload', 'has_speakers': False}
        elif request.form.get('text_content'):
            text_content = request.form.get('text_content', '').strip()
            transcription_info = {'service': 'Manual Input', 'has_speakers': False}
        
        if not text_content:
            return jsonify({'error': 'No content provided. Please upload a file or paste text.'}), 400
        
        # Get title from form
        title = request.form.get('title', 'Research Insights').strip()
        if not title:
            title = 'Research Insights'
        
        # Process with AI
        print(f"Processing transcript with {len(text_content)} characters...")
        insights = get_insights_from_llm(text_content)
        
        if not insights:
            return jsonify({'error': 'Failed to extract insights from the transcript. Please check your OpenAI API key.'}), 500
        
        # Add transcription metadata to insights
        insights['transcription_info'] = transcription_info
        
        # Generate presentation
        presentation = format_marp_presentation(title, insights)
        
        # Save to temp file
        filename = f"presentation_{uuid.uuid4().hex[:8]}.md"
        filepath = os.path.join(UPLOAD_FOLDER, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(presentation)
        
        return jsonify({
            'success': True,
            'insights': insights,
            'download_url': f'/download/{filename}',
            'preview': presentation[:500] + '...' if len(presentation) > 500 else presentation,
            'transcription': text_content[:200] + '...' if len(text_content) > 200 else text_content,
            'full_transcription': text_content,  # Include full transcription for display
            'transcription_info': transcription_info
        })
    
    except Exception as e:
        print(f"Error processing transcript: {str(e)}")
        return jsonify({'error': f'Processing failed: {str(e)}'}), 500

@app.route('/download/<filename>')
def download_file(filename):
    """Serve generated files for download."""
    return send_file(os.path.join(UPLOAD_FOLDER, filename), as_attachment=True)


@app.route('/export', methods=['POST'])
def export_presentation():
    """Export presentation in multiple formats (JSON, HTML, PDF)."""
    try:
        # Get the request data
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        export_format = data.get('format', 'json')
        insights = data.get('insights', {})
        transcript = data.get('transcript', '')
        transcription_info = data.get('transcription_info', {})
        title = data.get('title', 'Research Insights')
        template_style = data.get('template', 'professional')
        
        if not insights:
            return jsonify({'error': 'No insights provided for export'}), 400
        
        # Generate unique filename
        file_id = uuid.uuid4().hex[:8]
        
        if export_format.lower() == 'json':
            # Export as structured JSON
            export_data = {
                'metadata': {
                    'title': title,
                    'generated_at': datetime.now().isoformat(),
                    'service': transcription_info.get('service', 'Unknown'),
                    'has_speakers': transcription_info.get('has_speakers', False),
                    'speaker_count': transcription_info.get('speaker_count', 0),
                    'language': transcription_info.get('language', 'Auto-detected'),
                    'template': template_style,
                    'word_count': len(transcript.split()) if transcript else 0
                },
                'content': {
                    'transcript': transcript,
                    'summary': insights.get('summary', ''),
                    'themes': insights.get('themes', [])
                },
                'structure': {
                    'slides': generate_slide_structure(title, insights, template_style),
                    'presentation_notes': generate_presentation_notes(insights),
                    'appendix': {
                        'full_transcript': transcript,
                        'processing_details': transcription_info
                    }
                }
            }
            
            filename = f"insights_export_{file_id}.json"
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, indent=2, ensure_ascii=False)
        
        elif export_format.lower() == 'html':
            # Export as standalone HTML presentation
            html_content = generate_html_presentation(title, insights, transcript, transcription_info, template_style)
            
            filename = f"presentation_{file_id}.html"
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(html_content)
        
        elif export_format.lower() == 'markdown':
            # Enhanced Markdown with template styling
            markdown_content = generate_enhanced_markdown(title, insights, transcript, transcription_info, template_style)
            
            filename = f"presentation_{file_id}.md"
            filepath = os.path.join(UPLOAD_FOLDER, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(markdown_content)
        
        else:
            return jsonify({'error': f'Unsupported export format: {export_format}'}), 400
        
        return jsonify({
            'success': True,
            'filename': filename,
            'download_url': f'/download/{filename}',
            'format': export_format,
            'file_size': os.path.getsize(filepath)
        })
    
    except Exception as e:
        print(f"Export error: {str(e)}")
        return jsonify({'error': f'Failed to export presentation: {str(e)}'}), 500


def generate_slide_structure(title, insights, template_style):
    """Generate structured slide data for different templates."""
    slides = [
        {
            'id': 1,
            'type': 'title',
            'title': title,
            'subtitle': 'AI-Generated Research Insights',
            'template': template_style
        },
        {
            'id': 2,
            'type': 'summary',
            'title': 'Executive Summary',
            'content': insights.get('summary', ''),
            'template': template_style
        }
    ]
    
    # Add theme slides
    themes = insights.get('themes', [])
    for i, theme in enumerate(themes, 3):
        slides.append({
            'id': i,
            'type': 'theme',
            'title': f'Key Insight #{i-2}',
            'content': theme,
            'template': template_style
        })
    
    # Add conclusion slide
    slides.append({
        'id': len(slides) + 1,
        'type': 'conclusion',
        'title': 'Next Steps & Recommendations',
        'content': generate_recommendations(insights),
        'template': template_style
    })
    
    return slides


def generate_presentation_notes(insights):
    """Generate speaker notes for presentations."""
    notes = []
    
    # Summary notes
    notes.append({
        'slide': 2,
        'notes': f"This summary was generated from the research transcript. Key points to emphasize: {insights.get('summary', '')[:100]}..."
    })
    
    # Theme notes
    themes = insights.get('themes', [])
    for i, theme in enumerate(themes):
        notes.append({
            'slide': i + 3,
            'notes': f"Elaborate on this theme with specific examples from the research. Consider asking the audience about their experiences with: {theme}"
        })
    
    return notes


def generate_recommendations(insights):
    """Generate actionable recommendations based on insights."""
    themes = insights.get('themes', [])
    
    recommendations = [
        "Based on the research findings, we recommend:",
        ""
    ]
    
    for i, theme in enumerate(themes[:3], 1):  # Limit to top 3 themes
        recommendations.append(f"{i}. Address the key finding: '{theme}'")
    
    recommendations.extend([
        "",
        "Next steps:",
        "• Validate findings with larger user group",
        "• Prioritize improvements based on impact",
        "• Schedule follow-up research sessions"
    ])
    
    return "\n".join(recommendations)


def generate_html_presentation(title, insights, transcript, transcription_info, template_style):
    """Generate a standalone HTML presentation."""
    
    template_colors = {
        'professional': {'primary': '#2563eb', 'secondary': '#64748b', 'accent': '#f59e0b'},
        'creative': {'primary': '#7c3aed', 'secondary': '#ec4899', 'accent': '#10b981'},
        'minimal': {'primary': '#374151', 'secondary': '#6b7280', 'accent': '#059669'},
        'academic': {'primary': '#1e40af', 'secondary': '#475569', 'accent': '#dc2626'}
    }
    
    colors = template_colors.get(template_style, template_colors['professional'])
    
    html_content = f"""<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            color: #333;
        }}
        
        .presentation {{
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            overflow: hidden;
        }}
        
        .slide {{
            padding: 60px;
            border-bottom: 1px solid #e5e7eb;
            min-height: 400px;
            display: flex;
            flex-direction: column;
            justify-content: center;
        }}
        
        .slide:last-child {{
            border-bottom: none;
        }}
        
        .slide h1 {{
            color: {colors['primary']};
            font-size: 3rem;
            margin-bottom: 0.5rem;
            text-align: center;
        }}
        
        .slide h2 {{
            color: {colors['primary']};
            font-size: 2.5rem;
            margin-bottom: 1rem;
            border-bottom: 3px solid {colors['accent']};
            padding-bottom: 0.5rem;
        }}
        
        .slide h3 {{
            color: {colors['secondary']};
            font-size: 2rem;
            margin-bottom: 1rem;
        }}
        
        .subtitle {{
            color: {colors['secondary']};
            font-size: 1.5rem;
            text-align: center;
            margin-bottom: 2rem;
        }}
        
        .themes-list {{
            list-style: none;
            padding: 0;
        }}
        
        .themes-list li {{
            background: linear-gradient(135deg, {colors['primary']}10, {colors['accent']}10);
            margin: 1rem 0;
            padding: 1.5rem;
            border-left: 4px solid {colors['primary']};
            border-radius: 8px;
            font-size: 1.2rem;
        }}
        
        .metadata {{
            background: #f8fafc;
            padding: 2rem;
            border-top: 1px solid #e5e7eb;
            color: {colors['secondary']};
            font-size: 0.9rem;
        }}
        
        .metadata h4 {{
            color: {colors['primary']};
            margin-top: 0;
        }}
        
        @media (max-width: 768px) {{
            .slide {{
                padding: 30px 20px;
            }}
            
            .slide h1 {{
                font-size: 2rem;
            }}
            
            .slide h2 {{
                font-size: 1.8rem;
            }}
        }}
        
        @media print {{
            .slide {{
                page-break-inside: avoid;
                page-break-after: always;
            }}
            
            .slide:last-child {{
                page-break-after: auto;
            }}
        }}
    </style>
</head>
<body>
    <div class="presentation">
        <!-- Title Slide -->
        <div class="slide">
            <h1>{title}</h1>
            <div class="subtitle">AI-Generated Research Insights</div>
        </div>
        
        <!-- Summary Slide -->
        <div class="slide">
            <h2>Executive Summary</h2>
            <p style="font-size: 1.3rem; line-height: 1.8;">{insights.get('summary', 'No summary available')}</p>
        </div>
        
        <!-- Themes Slide -->
        <div class="slide">
            <h2>Key Themes Identified</h2>
            <ul class="themes-list">"""
    
    # Add themes
    for i, theme in enumerate(insights.get('themes', []), 1):
        html_content += f"""
                <li><strong>{i}.</strong> {theme}</li>"""
    
    html_content += f"""
            </ul>
        </div>
        
        <!-- Recommendations Slide -->
        <div class="slide">
            <h2>Next Steps & Recommendations</h2>
            <div style="font-size: 1.2rem; line-height: 1.8;">
                {generate_recommendations(insights).replace(chr(10), '<br>')}
            </div>
        </div>
    </div>
    
    <!-- Metadata Footer -->
    <div class="metadata">
        <h4>Processing Details</h4>
        <p><strong>Service:</strong> {transcription_info.get('service', 'Unknown')}</p>
        <p><strong>Speaker Diarization:</strong> {'✅ Enabled' if transcription_info.get('has_speakers') else '❌ Not available'}</p>
        <p><strong>Language:</strong> {transcription_info.get('language', 'Auto-detected')}</p>
        <p><strong>Generated:</strong> {datetime.now().strftime('%B %d, %Y at %I:%M %p')}</p>
        <p><strong>Template:</strong> {template_style.title()}</p>
    </div>
</body>
</html>"""
    
    return html_content


def generate_enhanced_markdown(title, insights, transcript, transcription_info, template_style):
    """Generate enhanced Markdown with template styling."""
    
    markdown_content = f"""---
marp: true
theme: {template_style}
class: invert
paginate: true
---

# {title}
## AI-Generated Research Insights

*Generated on {datetime.now().strftime('%B %d, %Y')}*

---

## 📋 Executive Summary

{insights.get('summary', 'No summary available')}

---

## 🔍 Key Themes Identified

"""
    
    # Add themes
    for i, theme in enumerate(insights.get('themes', []), 1):
        markdown_content += f"{i}. **{theme}**\n\n"
    
    markdown_content += f"""---

## 🚀 Next Steps & Recommendations

{generate_recommendations(insights)}

---

## 📊 Processing Details

| Detail | Value |
|--------|--------|
| **Service** | {transcription_info.get('service', 'Unknown')} |
| **Speaker Diarization** | {'✅ Enabled' if transcription_info.get('has_speakers') else '❌ Not available'} |
| **Language** | {transcription_info.get('language', 'Auto-detected')} |
| **Template** | {template_style.title()} |
| **Word Count** | {len(transcript.split()) if transcript else 0} words |

---

## 📝 Appendix: Full Transcript

```
{transcript[:1000]}{'...' if len(transcript) > 1000 else ''}
```

*Generated by InsightDeck Agent - Research-to-Presentation Automation*
"""
    
    return markdown_content

@app.route('/health')
def health_check():
    """Health check endpoint."""
    return jsonify({'status': 'healthy', 'message': 'InsightDeck Agent is running'})

@app.route('/process_demo', methods=['POST'])
def process_demo():
    try:
        data = request.get_json()
        demo_type = data.get('demo_type')
        service_type = data.get('service_type', 'whisper')
        
        # Map demo types to file names
        demo_files = {
            'user_interview': 'user_interview_dashboard.txt',
            'focus_group': 'focus_group_mobile_app.txt',
            'support_call': 'customer_support_call.txt',
            'team_meeting': 'team_standup_meeting.txt'
        }
        
        if demo_type not in demo_files:
            return jsonify({'error': 'Invalid demo type'})
        
        # Read the demo transcript file
        demo_file_path = os.path.join('sample_data', demo_files[demo_type])
        
        if not os.path.exists(demo_file_path):
            return jsonify({'error': f'Demo file not found: {demo_file_path}'})
        
        with open(demo_file_path, 'r', encoding='utf-8') as f:
            transcript = f.read()
        
        # Process the transcript (simulate the selected service)
        if service_type == 'elevenlabs':
            # Format as if it came from ElevenLabs with speakers
            transcript_data = {
                'transcript': transcript,
                'has_speakers': True,
                'speaker_count': len(set(re.findall(r'^([^:]+):', transcript, re.MULTILINE))),
                'service': 'ElevenLabs (Demo)',
                'language': 'en'
            }
        else:
            # Format as plain Whisper transcript (no speakers)
            # Remove speaker labels for Whisper simulation
            plain_transcript = re.sub(r'^[^:]+:\s*', '', transcript, flags=re.MULTILINE)
            transcript_data = {
                'transcript': plain_transcript,
                'has_speakers': False,
                'speaker_count': 0,
                'service': 'OpenAI Whisper (Demo)',
                'language': 'en'
            }
        
        # Get insights using the main processing function
        insights = get_insights_from_llm(transcript_data['transcript'])
        
        # Generate download file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"demo_{demo_type}_{timestamp}.md"
        filepath = os.path.join('outputs', filename)
        
        # Create outputs directory if it doesn't exist
        os.makedirs('outputs', exist_ok=True)
        
        # Generate markdown content
        content = generate_markdown_content(transcript_data['transcript'], insights, transcript_data)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return jsonify({
            'insights': insights,
            'transcription_info': transcript_data,
            'download_url': f'/download/{filename}'
        })
        
    except Exception as e:
        return jsonify({'error': f'Failed to process demo: {str(e)}'})

@app.route('/api/config', methods=['GET'])
def get_config():
    """Get current configuration status."""
    openai_key = os.getenv('OPENAI_API_KEY', '')
    elevenlabs_key = os.getenv('ELEVENLABS_API_KEY', '')
    
    # Mask keys for security (show only first 8 and last 4 characters)
    openai_masked = ''
    elevenlabs_masked = ''
    
    if openai_key and len(openai_key) > 12:
        openai_masked = openai_key[:8] + '...' + openai_key[-4:]
    
    if elevenlabs_key and len(elevenlabs_key) > 12:
        elevenlabs_masked = elevenlabs_key[:8] + '...' + elevenlabs_key[-4:]
    
    return jsonify({
        'openai_configured': bool(openai_key and openai_key != 'your_openai_api_key_here'),
        'elevenlabs_configured': bool(elevenlabs_key and elevenlabs_key != 'your_elevenlabs_api_key_here'),
        'openai_key_preview': openai_masked,
        'elevenlabs_key_preview': elevenlabs_masked
    })

@app.route('/api/config', methods=['POST'])
def save_config():
    """Save API configuration."""
    try:
        data = request.get_json()
        openai_key = data.get('openai_key', '').strip()
        elevenlabs_key = data.get('elevenlabs_key', '').strip()
        
        # Update environment variables
        if openai_key:
            os.environ['OPENAI_API_KEY'] = openai_key
        if elevenlabs_key:
            os.environ['ELEVENLABS_API_KEY'] = elevenlabs_key
        
        # Update .env file
        env_path = '.env'
        env_content = []
        
        # Read existing .env file
        if os.path.exists(env_path):
            with open(env_path, 'r') as f:
                env_content = f.readlines()
        
        # Update or add keys
        openai_updated = False
        elevenlabs_updated = False
        
        for i, line in enumerate(env_content):
            if line.startswith('OPENAI_API_KEY=') and openai_key:
                env_content[i] = f'OPENAI_API_KEY={openai_key}\n'
                openai_updated = True
            elif line.startswith('ELEVENLABS_API_KEY=') and elevenlabs_key:
                env_content[i] = f'ELEVENLABS_API_KEY={elevenlabs_key}\n'
                elevenlabs_updated = True
        
        # Add new keys if not found
        if openai_key and not openai_updated:
            env_content.append(f'OPENAI_API_KEY={openai_key}\n')
        if elevenlabs_key and not elevenlabs_updated:
            env_content.append(f'ELEVENLABS_API_KEY={elevenlabs_key}\n')
        
        # Write updated .env file
        with open(env_path, 'w') as f:
            f.writelines(env_content)
        
        return jsonify({'success': True, 'message': 'Configuration saved successfully'})
        
    except Exception as e:
        return jsonify({'error': f'Failed to save configuration: {str(e)}'})

@app.route('/api/test-openai', methods=['POST'])
def test_openai():
    """Test OpenAI API connectivity."""
    try:
        data = request.get_json()
        api_key = data.get('api_key', '').strip()
        
        if not api_key:
            api_key = os.getenv('OPENAI_API_KEY', '')
        
        if not api_key or api_key == 'your_openai_api_key_here':
            return jsonify({'error': 'No valid OpenAI API key provided'})
        
        # Test the API key with a simple request
        from openai import OpenAI
        client = OpenAI(api_key=api_key)
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "Test connection - respond with 'OK'"}],
            max_tokens=5
        )
        
        return jsonify({
            'success': True, 
            'message': 'OpenAI API connection successful',
            'model': 'gpt-4o-mini',
            'response': response.choices[0].message.content
        })
        
    except Exception as e:
        return jsonify({'error': f'OpenAI API test failed: {str(e)}'})

@app.route('/api/test-elevenlabs', methods=['POST'])
def test_elevenlabs():
    """Test ElevenLabs API connectivity."""
    try:
        data = request.get_json()
        api_key = data.get('api_key', '').strip()
        
        if not api_key:
            api_key = os.getenv('ELEVENLABS_API_KEY', '')
        
        if not api_key or api_key == 'your_elevenlabs_api_key_here':
            return jsonify({'error': 'No valid ElevenLabs API key provided'})
        
        # Test the API key with a simple request to get user info
        headers = {'xi-api-key': api_key}
        response = requests.get('https://api.elevenlabs.io/v1/user', headers=headers)
        
        if response.status_code == 200:
            user_data = response.json()
            return jsonify({
                'success': True,
                'message': 'ElevenLabs API connection successful',
                'subscription': user_data.get('subscription', {}).get('tier', 'unknown'),
                'character_count': user_data.get('subscription', {}).get('character_count', 0),
                'character_limit': user_data.get('subscription', {}).get('character_limit', 0)
            })
        else:
            return jsonify({'error': f'ElevenLabs API test failed: HTTP {response.status_code}'})
        
    except Exception as e:
        return jsonify({'error': f'ElevenLabs API test failed: {str(e)}'})

@app.route('/api/combine-batch', methods=['POST'])
def combine_batch():
    """Combine results from multiple files into a comprehensive report."""
    try:
        data = request.get_json()
        files = data.get('files', [])
        title = data.get('title', 'Batch Analysis Results')
        service_type = data.get('service_type', 'whisper')
        
        if not files:
            return jsonify({'error': 'No files provided for batch processing'})
        
        # Combine all transcripts
        all_transcripts = []
        all_insights = []
        successful_files = []
        failed_files = []
        
        for file_data in files:
            filename = file_data.get('filename', 'Unknown')
            
            if 'error' in file_data:
                failed_files.append({
                    'filename': filename,
                    'error': file_data['error']
                })
                continue
                
            result = file_data.get('result', {})
            if result.get('insights'):
                all_transcripts.append(f"## {filename}\n\n{result.get('transcription_info', {}).get('transcript', '')}")
                all_insights.append(result['insights'])
                successful_files.append(filename)
        
        if not successful_files:
            return jsonify({'error': 'No files were successfully processed'})
        
        # Combine transcripts
        combined_transcript = "\n\n---\n\n".join(all_transcripts)
        
        # Generate combined insights
        combined_insights = combine_multiple_insights(all_insights, successful_files)
        
        # Create combined transcription info
        combined_transcription_info = {
            'transcript': combined_transcript,
            'service': f'{service_type.title()} (Batch Processing)',
            'language': 'Auto-detected',
            'has_speakers': any(insight.get('transcription_info', {}).get('has_speakers', False) for insight in [f.get('result', {}) for f in files]),
            'speaker_count': sum(insight.get('transcription_info', {}).get('speaker_count', 0) for insight in [f.get('result', {}) for f in files]),
            'files_processed': len(successful_files),
            'failed_files': len(failed_files)
        }
        
        # Generate download file
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"batch_analysis_{timestamp}.md"
        filepath = os.path.join('outputs', filename)
        
        # Create outputs directory if it doesn't exist
        os.makedirs('outputs', exist_ok=True)
        
        # Generate enhanced markdown content for batch
        content = generate_batch_markdown_content(combined_transcript, combined_insights, combined_transcription_info, successful_files, failed_files)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return jsonify({
            'insights': combined_insights,
            'transcription_info': combined_transcription_info,
            'download_url': f'/download/{filename}',
            'batch_summary': {
                'total_files': len(files),
                'successful_files': len(successful_files),
                'failed_files': len(failed_files),
                'successful_filenames': successful_files,
                'failed_filenames': [f['filename'] for f in failed_files]
            }
        })
        
    except Exception as e:
        return jsonify({'error': f'Failed to combine batch results: {str(e)}'})

def combine_multiple_insights(insights_list, filenames):
    """Combine insights from multiple files into a comprehensive analysis."""
    if not insights_list:
        return {}
    
    # Combine all themes
    all_themes = []
    for insights in insights_list:
        if insights.get('themes'):
            all_themes.extend(insights['themes'])
    
    # Remove duplicates and get most common themes
    theme_counts = {}
    for theme in all_themes:
        theme_lower = theme.lower()
        theme_counts[theme_lower] = theme_counts.get(theme_lower, 0) + 1
    
    # Get top themes
    sorted_themes = sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)
    combined_themes = [theme for theme, count in sorted_themes[:10]]  # Top 10 themes
    
    # Create combined summary
    file_summaries = []
    for i, insights in enumerate(insights_list):
        if insights.get('summary') and i < len(filenames):
            file_summaries.append(f"**{filenames[i]}:** {insights['summary']}")
    
    combined_summary = f"""This batch analysis combines insights from {len(filenames)} files:

{chr(10).join(file_summaries)}

**Overall Analysis:** The combined data reveals consistent patterns across multiple sources, providing comprehensive insights into the research topics."""
    
    return {
        'summary': combined_summary,
        'themes': combined_themes,
        'batch_info': {
            'files_analyzed': len(filenames),
            'total_themes_found': len(all_themes),
            'unique_themes': len(set(all_themes))
        }
    }

def generate_batch_markdown_content(transcript, insights, transcript_info, successful_files, failed_files):
    """Generate enhanced markdown content for batch analysis."""
    content = f"""# 📊 Batch Analysis Report

## 🎯 Processing Summary
- **Total Files Processed**: {transcript_info.get('files_processed', 0)}
- **Service Used**: {transcript_info.get('service', 'Unknown')}
- **Language**: {transcript_info.get('language', 'Auto-detected')}
- **Generated**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

### ✅ Successfully Processed Files
{chr(10).join([f"- {filename}" for filename in successful_files])}

"""
    
    if failed_files:
        content += f"""### ❌ Failed Files
{chr(10).join([f"- {file['filename']}: {file.get('error', 'Unknown error')}" for file in failed_files])}

"""
    
    content += f"""## 📋 Combined Executive Summary
{insights.get('summary', 'Summary not available')}

## 🔍 Key Themes Across All Files
"""
    
    if insights.get('themes'):
        for i, theme in enumerate(insights['themes'], 1):
            content += f"{i}. {theme}\n"
    else:
        content += "No themes identified\n"
    
    if insights.get('batch_info'):
        batch_info = insights['batch_info']
        content += f"""
## 📈 Analysis Statistics
- **Files Analyzed**: {batch_info.get('files_analyzed', 0)}
- **Total Themes Found**: {batch_info.get('total_themes_found', 0)}
- **Unique Themes**: {batch_info.get('unique_themes', 0)}
"""
    
    content += f"""
## 📝 Combined Transcriptions
{transcript}

---
*Generated by InsightDeck - AI-Powered Batch Analysis*
"""
    
    return content

if __name__ == '__main__':
    print("🚀 Starting InsightDeck Agent Web Interface...")
    print("📝 Make sure your OPENAI_API_KEY environment variable is set!")
    print("🌐 Open http://localhost:8080 in your browser")
    app.run(debug=True, host='127.0.0.1', port=8080)